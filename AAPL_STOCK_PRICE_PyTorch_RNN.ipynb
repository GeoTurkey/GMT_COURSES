{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AAPL_STOCK_PRICE_PyTorch_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GeoTurkey/GMT_COURSES/blob/main/AAPL_STOCK_PRICE_PyTorch_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkTeSRVsokNy"
      },
      "source": [
        "# RNN Exercises\n",
        "\n",
        "\n",
        "In the exercises below you'll be asked to do the following:\n",
        "* Perform standard imports, load & plot the dataset (code provided)\n",
        "* Prepare data for an LSTM model\n",
        "* Define the LSTM model, loss and optimization functions\n",
        "* Train the model\n",
        "* Evaluate the model on test data\n",
        "* OPTIONAL: Plot the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUkjJwwgokNy"
      },
      "source": [
        "## Perform standard imports, load and plot the dataset\n",
        "Run the cells below to load the libraries needed for this exercise and the Energy Production dataset, and to plot the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "hogehVANokNy",
        "outputId": "51322f71-9054-4c53-f268-377c521327e4"
      },
      "source": [
        "# RUN THIS CELL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_datareader as web\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "register_matplotlib_converters()\n",
        "\n",
        "#Get the stock quote \n",
        "#df = web.DataReader('AAPL', data_source='yahoo', start='2000-01-01', end='2020-10-15')\n",
        "df = web.DataReader('AMZN', data_source='yahoo', start='2006-01-01', end='2018-01-01') \n",
        "\n",
        "#Show the data \n",
        "df\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Adj Close</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-01-03</th>\n",
              "      <td>47.849998</td>\n",
              "      <td>46.250000</td>\n",
              "      <td>47.470001</td>\n",
              "      <td>47.580002</td>\n",
              "      <td>7582200</td>\n",
              "      <td>47.580002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-01-04</th>\n",
              "      <td>47.730000</td>\n",
              "      <td>46.689999</td>\n",
              "      <td>47.490002</td>\n",
              "      <td>47.250000</td>\n",
              "      <td>7440900</td>\n",
              "      <td>47.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-01-05</th>\n",
              "      <td>48.200001</td>\n",
              "      <td>47.110001</td>\n",
              "      <td>47.160000</td>\n",
              "      <td>47.650002</td>\n",
              "      <td>5417200</td>\n",
              "      <td>47.650002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-01-06</th>\n",
              "      <td>48.580002</td>\n",
              "      <td>47.320000</td>\n",
              "      <td>47.970001</td>\n",
              "      <td>47.869999</td>\n",
              "      <td>6152900</td>\n",
              "      <td>47.869999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-01-09</th>\n",
              "      <td>47.099998</td>\n",
              "      <td>46.400002</td>\n",
              "      <td>46.549999</td>\n",
              "      <td>47.080002</td>\n",
              "      <td>8943100</td>\n",
              "      <td>47.080002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-22</th>\n",
              "      <td>1174.619995</td>\n",
              "      <td>1167.829956</td>\n",
              "      <td>1172.079956</td>\n",
              "      <td>1168.359985</td>\n",
              "      <td>1585100</td>\n",
              "      <td>1168.359985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-26</th>\n",
              "      <td>1178.319946</td>\n",
              "      <td>1160.550049</td>\n",
              "      <td>1168.359985</td>\n",
              "      <td>1176.760010</td>\n",
              "      <td>2005200</td>\n",
              "      <td>1176.760010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-27</th>\n",
              "      <td>1187.290039</td>\n",
              "      <td>1175.609985</td>\n",
              "      <td>1179.910034</td>\n",
              "      <td>1182.260010</td>\n",
              "      <td>1867200</td>\n",
              "      <td>1182.260010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-28</th>\n",
              "      <td>1190.099976</td>\n",
              "      <td>1184.380005</td>\n",
              "      <td>1189.000000</td>\n",
              "      <td>1186.099976</td>\n",
              "      <td>1841700</td>\n",
              "      <td>1186.099976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2017-12-29</th>\n",
              "      <td>1184.000000</td>\n",
              "      <td>1167.500000</td>\n",
              "      <td>1182.349976</td>\n",
              "      <td>1169.469971</td>\n",
              "      <td>2688400</td>\n",
              "      <td>1169.469971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3020 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                   High          Low  ...   Volume    Adj Close\n",
              "Date                                  ...                      \n",
              "2006-01-03    47.849998    46.250000  ...  7582200    47.580002\n",
              "2006-01-04    47.730000    46.689999  ...  7440900    47.250000\n",
              "2006-01-05    48.200001    47.110001  ...  5417200    47.650002\n",
              "2006-01-06    48.580002    47.320000  ...  6152900    47.869999\n",
              "2006-01-09    47.099998    46.400002  ...  8943100    47.080002\n",
              "...                 ...          ...  ...      ...          ...\n",
              "2017-12-22  1174.619995  1167.829956  ...  1585100  1168.359985\n",
              "2017-12-26  1178.319946  1160.550049  ...  2005200  1176.760010\n",
              "2017-12-27  1187.290039  1175.609985  ...  1867200  1182.260010\n",
              "2017-12-28  1190.099976  1184.380005  ...  1841700  1186.099976\n",
              "2017-12-29  1184.000000  1167.500000  ...  2688400  1169.469971\n",
              "\n",
              "[3020 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtedMSaKtfmo",
        "outputId": "9994ae53-947c-4279-d518-1181ccdad092"
      },
      "source": [
        "torch.cuda.is_available()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "ikixImzrtlKt",
        "outputId": "ce09974d-42c4-4941-f44e-057bcb26a0d4"
      },
      "source": [
        "torch.cuda.current_device()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-3380d2c12118>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;34mr\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbD-osvZtlzm"
      },
      "source": [
        "torch.cuda.get_device_name(0) # Get name device with ID '0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfpc0vqGtpve"
      },
      "source": [
        "torch.cuda.memory_allocated()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cynl2W5Ntpyk"
      },
      "source": [
        "torch.cuda.memory_reserved()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHodEKXw6m4v"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7dPZTbIokN1"
      },
      "source": [
        "#Visualize the closing price history\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.title('Close Price History')\n",
        "plt.plot(df['Close'])\n",
        "plt.xlabel('Date',fontsize=18)\n",
        "plt.ylabel('Close Price USD ($)',fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2AyYxdZxGLw"
      },
      "source": [
        "#Create a new dataframe with only the 'Close' column\n",
        "data = df.filter(['Close'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x88-KcYdxI0M"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INPzV1B0okN2"
      },
      "source": [
        "# Prepare the data\n",
        "For the first set of exercises we'll\n",
        "* divide the data into train and test sets\n",
        "* normalize the training set\n",
        "* prepare windowed seq/label tuples for an LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pULJ9MsOokN2"
      },
      "source": [
        "## 1. Divide the data into train and test sets\n",
        "Working with a window_size of 12, divide the dataset into a sequence of 313 training records (including the window), and a test set of 12 records."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uO_tdrVokN3"
      },
      "source": [
        "## 2. Normalize the training set\n",
        "Feature scale the training set to fit within the range [-1,1]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUr4B1qlokN4"
      },
      "source": [
        "y = data.values.astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WC0M9YsmJ5Q"
      },
      "source": [
        "train_size = int(len(y) * 0.8) \n",
        "test_size = len(y) - train_size\n",
        "window_size = 60\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfcWVeMemJ8T"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "data_norm = scaler.fit_transform(y.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GGp5tF9mJ_H"
      },
      "source": [
        "train_set = data_norm[:train_size]\n",
        "test_set = data_norm[train_size:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwcVOUo-okN2"
      },
      "source": [
        "# Run the code below to check your results:\n",
        "print(f'Train: {len(train_set)}')\n",
        "print(f'Test:  {len(test_set)}')\n",
        "print(f'Train Shape: {train_set.shape}')\n",
        "print(f'Test Shape:  {test_set.shape}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXRC2drqokN2"
      },
      "source": [
        "# DON'T WRITE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caMf6flGokN4"
      },
      "source": [
        "# Run the code below to check your results:\n",
        "print(f'First item, original: {y[0]}')\n",
        "print(f'First item, scaled:  {train_set[0]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfHRRYPBokN4"
      },
      "source": [
        "# DON'T WRITE HERE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bR15yJOokN4"
      },
      "source": [
        "## 3. Prepare data for LSTM\n",
        "Prepare the list of windowed sequence/label tuples to be fed into an LSTM model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcuzybTyokN4"
      },
      "source": [
        "# RUN THIS CELL\n",
        "\n",
        "def create_dataset_train(X,ws=1):\n",
        "  Xs, ys = [], []\n",
        "  for i in range (len(X) - ws):\n",
        "    v = X[i:i+ws]\n",
        "    Xs.append(v)\n",
        "    ys.append(X[i+ws:i+ws+1,0])\n",
        "  return np.array(Xs), np.array(ys)\n",
        "\n",
        "x_train, y_train = create_dataset_train(train_set, window_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrpBdIpVOKa2"
      },
      "source": [
        "test_set_2 = data_norm[train_size - window_size:]\n",
        "\n",
        "def create_dataset_test(X,ws=1):\n",
        "  Xs, ys = [], []\n",
        "  for i in range (len(X) - ws):\n",
        "    v = X[i:i+ws]\n",
        "    Xs.append(v)\n",
        "    ys.append(X[i+ws:i+ws+1,0])\n",
        "  return np.array(Xs), np.array(ys)\n",
        "\n",
        "x_test, y_test = create_dataset_test(test_set_2, window_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHvdaBT2TO0J"
      },
      "source": [
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEbfy0NCTO3K"
      },
      "source": [
        "x_train = torch.from_numpy(x_train).type(torch.Tensor).cuda()\n",
        "x_test = torch.from_numpy(x_test).type(torch.Tensor).cuda()\n",
        "y_train_lstm = torch.from_numpy(y_train).type(torch.Tensor).cuda()\n",
        "y_test_lstm = torch.from_numpy(y_test).type(torch.Tensor).cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pI3MWczsokN5"
      },
      "source": [
        "## 4. Define the model\n",
        "Design a model that has a (1,64) LSTM layer and a (64,1) fully-connected linear layer. Be sure to initialize $h_0$ and $c_0$, and return only the last predicted value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUqqTxAmUrD3"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        \n",
        "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().cuda()\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).requires_grad_().cuda()\n",
        "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
        "        out = self.fc(out[:, -1, :]) \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDb6oiAYUrH6"
      },
      "source": [
        "model = LSTM(input_dim=1, hidden_dim=512, output_dim=1, num_layers=1).cuda()\n",
        "criterion = torch.nn.MSELoss()\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuNAuVnf7M_T"
      },
      "source": [
        "next(model.parameters()).is_cuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPPWxu4o-oqH"
      },
      "source": [
        "for m in model.parameters():\n",
        "    print(m.device) #return cuda:0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_5S3hbIUzwP"
      },
      "source": [
        "import time\n",
        "num_epochs = 400\n",
        "hist = np.zeros(num_epochs)\n",
        "hist_val = np.zeros(num_epochs)\n",
        "start_time = time.time()\n",
        "\n",
        "for t in range(num_epochs):\n",
        "    model.train()\n",
        "    y_train_pred = model(x_train)\n",
        "\n",
        "    loss = criterion(y_train_pred, y_train_lstm)\n",
        "    hist[t] = loss.item()\n",
        "\n",
        "    optimiser.zero_grad()\n",
        "    loss.backward()\n",
        "    optimiser.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      y_test_pred = model(x_test)\n",
        "      val_loss = criterion(y_test_pred, y_test_lstm)\n",
        "      hist_val[t] = val_loss.item()\n",
        "    \n",
        "    if t % 10 == 0 and t !=0:\n",
        "      print(\"Epoch \", t, \"Train Loss: {}  Val Loss: {}\".format(loss.item(), val_loss.item()))\n",
        "\n",
        "training_time = time.time()-start_time\n",
        "print(\"Training time: {}\".format(training_time))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_TftiRTDUzy4"
      },
      "source": [
        "plt.plot(hist)\n",
        "plt.plot(hist_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5IdtquZokN8"
      },
      "source": [
        "## 10. Inverse transform the train and predicted values\n",
        "Rescale the predicted values up to the original test set range."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Up-2AqmzokN8"
      },
      "source": [
        "# invert predictions\n",
        "y_train_pred = scaler.inverse_transform(y_train_pred.detach().cpu().numpy())\n",
        "y_train = scaler.inverse_transform(y_train_lstm.detach().cpu().numpy())\n",
        "y_test_pred = scaler.inverse_transform(y_test_pred.detach().cpu().numpy())\n",
        "y_test = scaler.inverse_transform(y_test_lstm.detach().cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEoimR7G8VP-"
      },
      "source": [
        "train_data = data[:train_size-window_size]\n",
        "train_data[\"Train Predict\"] = y_train_pred\n",
        "valid = data[train_size:]\n",
        "valid[\"Test\"] = y_test \n",
        "valid['True Predictions'] = y_test_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mv4uZvlGK1ji"
      },
      "source": [
        "train_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dEYU0mVK1m6"
      },
      "source": [
        "valid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYtkIs13okN9"
      },
      "source": [
        "## BONUS EXERCISE: Plot the result\n",
        "Plot the true_predictions values together with the original data. Remember to create a range of datetime values for the predicted data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYsHGi_-tKFZ"
      },
      "source": [
        "train_data.plot(figsize=(18,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0lVOGANsbAv"
      },
      "source": [
        "valid.plot(figsize=(18,10));"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqUMR5nOsbH5"
      },
      "source": [
        "data.plot(figsize=(22,10))\n",
        "#train_data['Train_Predict'].plot()\n",
        "valid['True Predictions'].plot()\n",
        "train_data[\"Train Predict\"].plot()\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raTOgIp7Qgnj"
      },
      "source": [
        "# calculate root mean squared error of the training result based on last iteration (epoch) and non-scaled values.\n",
        "\n",
        "trainScore = math.sqrt(mean_squared_error(y_train_pred, y_train))\n",
        "print('Train Score: %.4f RMSE' % (trainScore))\n",
        "testScore = math.sqrt(mean_squared_error(y_test_pred, y_test))\n",
        "print('Test Score: %.4f RMSE' % (testScore))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcHwdUVaokN-"
      },
      "source": [
        "## Great job!"
      ]
    }
  ]
}